from sympy import Symbol, lambdify
import matplotlib.pyplot as plt
import numpy as np

x = Symbol('x')

function = (x + 3)**2

function_lambda = lambdify(x, function)

def gradient_descent(function, start, learn_rate, n_iter=10000, tolerance=1e-06, step_size=1):
    gradient = lambdify(x, function.diff(x))
    function = lambdify(x, function)
    points = [start]
    iters = 0 
    
    while step_size > tolerance and iters < n_iter:
        prev_x = start  
        start = start - learn_rate * gradient(prev_x)  
        step_size = abs(start - prev_x)  
        iters = iters + 1  
        points.append(start)

    print("The local minimum occurs at", start)

    x_ = np.linspace(-7, 5, 100)
    y = function_lambda(x_)

    plt.plot(x_, y, 'r', label='Function')
    plt.plot(points, [function_lambda(p) for p in points], '-o', label='Optimization Path')
    plt.xlabel('x')
    plt.ylabel('y')
    plt.title('Gradient Descent Optimization')
    plt.legend()
    plt.grid(False)
    plt.show()

gradient_descent(function, start=2.0, learn_rate=0.2, n_iter=50)
